# Stage 5 Configuration: Advanced Ensemble
# Combines models from Stages 3-5 for optimal performance

ensemble:
  # Ensemble method
  method: "learned_weights"  # simple_average, learned_weights, fixed_weights, stacking
  
  # Model selection
  include_stage3: true
  include_stage4: true
  include_stage5: true
  
  # Cross-validation for model selection
  cv_folds: 5
  selection_metric: "auc"
  min_models: 3
  max_models: 8
  
  # Ensemble architecture
  weight_learner:
    hidden_dim: 64
    dropout: 0.2
    
  # Meta-learner for stacking
  meta_learner:
    hidden_dims: [64, 32]
    dropout: 0.2
    activation: "relu"

# Training configuration
training:
  epochs: 50  # Shorter since base models are pre-trained
  batch_size: 32
  learning_rate: 1e-3
  weight_decay: 1e-4
  
  # Fine-tuning
  freeze_base_models: true
  unfreeze_after_epoch: 20
  
  # Validation
  val_ratio: 0.15
  test_ratio: 0.15

# Stage 3 Models (Graph Models)
stage3_models:
  - name: "han_baseline"
    config: "configs/han.yaml"
    weight: 1.0
    
  - name: "gcn_enhanced"
    config: "configs/gcn.yaml"
    weight: 0.8

# Stage 4 Models (Temporal Models)
stage4_models:
  - name: "simple_lstm"
    config: "configs/temporal.yaml"
    weight: 1.0
    
  - name: "simple_gru"
    config: "configs/temporal.yaml"
    weight: 0.9
    
  - name: "temporal_mlp"
    config: "configs/temporal.yaml"
    weight: 0.7

# Stage 5 Models (Advanced Models)
stage5_models:
  - name: "graph_transformer"
    config: "configs/stage5/graph_transformer.yaml"
    weight: 1.2
    
  - name: "hetero_graph_transformer"
    config: "configs/stage5/hetero_graph_transformer.yaml"
    weight: 1.1
    
  - name: "temporal_graph_transformer"
    config: "configs/stage5/temporal_graph_transformer.yaml"
    weight: 1.3

# Data configuration
dataset:
  name: "ellipticpp_ensemble"
  data_dir: "data/ellipticpp"
  
  # Multi-modal data preparation
  prepare_graph_data: true
  prepare_temporal_data: true
  prepare_hetero_data: true
  
  # Feature alignment
  align_features: true
  common_feature_dim: 186

# Evaluation configuration
evaluation:
  metrics:
    - "auc"
    - "f1"
    - "precision"
    - "recall"
    - "accuracy"
    - "ensemble_diversity"
    - "model_agreement"
  
  # Cross-validation evaluation
  cv_evaluation: true
  bootstrap_samples: 100
  confidence_interval: 0.95
  
  # Individual model analysis
  analyze_individual_models: true
  compute_model_importance: true

# Output configuration
output:
  save_ensemble: true
  save_individual_predictions: true
  save_ensemble_weights: true
  save_model_analysis: true
  
  # Directories
  model_dir: "experiments/stage5/ensemble"
  log_dir: "logs/stage5/ensemble"
  analysis_dir: "analysis/stage5/ensemble"

# Hardware configuration
hardware:
  device: "auto"
  mixed_precision: false
  num_workers: 4
  pin_memory: true
  
  # Memory management
  max_memory_usage: 0.8
  batch_size_auto_adjust: true

# Reproducibility
seed: 42

# Advanced options
advanced:
  # Ensemble diversity
  diversity_regularization: 0.01
  disagreement_penalty: 0.005
  
  # Model calibration
  temperature_scaling: true
  platt_scaling: false
  
  # Uncertainty quantification
  monte_carlo_dropout: true
  mc_samples: 100
  
  # Interpretability
  compute_shapley_values: true
  analyze_feature_importance: true
  save_attention_maps: true
  
  # Monitoring
  log_interval: 50
  eval_interval: 200
  
  # Performance optimization
  parallel_prediction: true
  batch_parallel: true
