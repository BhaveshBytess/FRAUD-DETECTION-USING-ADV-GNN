# experiments/stage6_experiments.py
"""
Stage 6 TDGNN + G-SAMPLER Experimental Framework per Â§PHASE_D.1-D.3
Comprehensive comparison and ablation studies for temporal fraud detection
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))

import torch
import torch.nn as nn
import torch.nn.functional as F
                        val_preds = torch.softmax(val_logits[val_mask], dim=1)[:, 1]
                        val_metrics = compute_metrics(labels[val_mask].numpy(), val_preds.numpy())
                        
                        if val_metrics['f1'] > best_val_acc:
                            best_val_acc = val_metrics['f1']t numpy as np
import pandas as pd
import json
import time
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from typing import Dict, List, Any, Tuple
import logging
from datetime import datetime

# TDGNN imports
from models.tdgnn_wrapper import TDGNNHypergraphModel, train_epoch, evaluate_model
from models.hypergraph import create_hypergraph_model, HypergraphData
from sampling.gsampler import GSampler
from sampling.cpu_fallback import TemporalGraph
from torch.utils.data import DataLoader, TensorDataset

# Baseline model imports
from models.gcn_baseline import SimpleGCN
from models.graphsage_baseline import SimpleGraphSAGE
from models.rgcn_baseline import SimpleRGCN
from models.han_baseline import SimpleHAN

# Utility imports
from metrics import compute_metrics
from utils import set_seed

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class Stage6ExperimentFramework:
    """
    Comprehensive experimental framework for Stage 6 TDGNN + G-SAMPLER
    Implements Â§PHASE_D.1-D.3 experiments and ablation studies
    """
    
    def __init__(self, results_dir: str = "experiments/stage6_results"):
        """Initialize experimental framework"""
        self.results_dir = Path(results_dir)
        self.results_dir.mkdir(parents=True, exist_ok=True)
        
        # Experiment tracking
        self.experiment_results = {}
        self.timing_results = {}
        self.memory_results = {}
        
        # Set random seed for reproducibility
        set_seed(42)
        
        logger.info(f"Stage 6 Experiment Framework initialized - Results: {self.results_dir}")
    
    def create_synthetic_temporal_data(self, num_nodes: int = 1000, num_edges: int = 3000, 
                                     feature_dim: int = 64) -> Tuple[TemporalGraph, HypergraphData, torch.Tensor, torch.Tensor]:
        """Create synthetic temporal fraud detection dataset"""
        logger.info(f"Creating synthetic temporal dataset: {num_nodes} nodes, {num_edges} edges")
        
        # Generate realistic temporal graph
        edges = torch.randint(0, num_nodes, (2, num_edges))
        
        # Create temporal patterns: recent edges have higher timestamps
        base_time = 1000.0
        temporal_decay = torch.exp(-torch.rand(num_edges) * 2)  # Exponential decay
        timestamps = base_time + temporal_decay * 500  # Recent bias
        
        # Sort by source node for CSR format
        edge_data = list(zip(edges[0].tolist(), edges[1].tolist(), timestamps.tolist()))
        edge_data.sort(key=lambda x: (x[0], -x[2]))  # Sort by source, then by time descending
        
        # Build CSR structure
        indptr = torch.zeros(num_nodes + 1, dtype=torch.long)
        indices = []
        edge_times = []
        
        current_node = 0
        for src, dst, time in edge_data:
            while current_node < src:
                indptr[current_node + 1] = len(indices)
                current_node += 1
            
            indices.append(dst)
            edge_times.append(time)
        
        # Fill remaining indptr entries
        while current_node < num_nodes:
            indptr[current_node + 1] = len(indices)
            current_node += 1
        
        temporal_graph = TemporalGraph(
            num_nodes=num_nodes,
            num_edges=len(indices),
            indptr=indptr,
            indices=torch.tensor(indices, dtype=torch.long),
            timestamps=torch.tensor(edge_times)
        )
        
        # Create hypergraph data with meaningful communities
        num_hyperedges = min(50, num_nodes // 10)
        incidence_matrix = torch.zeros(num_nodes, num_hyperedges)
        
        # Create overlapping communities
        for he in range(num_hyperedges):
            community_size = torch.randint(8, 20, (1,)).item()
            center_node = torch.randint(0, num_nodes, (1,)).item()
            
            # Add center node and nearby nodes (simulate geographical/behavioral clustering)
            community_nodes = [center_node]
            while len(community_nodes) < community_size:
                candidate = torch.randint(0, num_nodes, (1,)).item()
                if candidate not in community_nodes:
                    community_nodes.append(candidate)
            
            for node in community_nodes:
                incidence_matrix[node, he] = 1.0
        
        # Create realistic node features (transaction features)
        node_features = torch.randn(num_nodes, feature_dim)
        
        # Add feature correlations that matter for fraud detection
        # Feature 0-15: transaction amounts (log-normal distribution)
        node_features[:, :16] = torch.log(torch.abs(torch.randn(num_nodes, 16)) + 0.1)
        
        # Feature 16-31: temporal patterns
        node_features[:, 16:32] = torch.sin(torch.randn(num_nodes, 16) * 2 * np.pi)
        
        # Feature 32-47: network features (degree, centrality proxies)
        degrees = torch.bincount(torch.cat([edges[0], edges[1]]), minlength=num_nodes).float()
        node_features[:, 32] = torch.log(degrees + 1)  # Log degree
        node_features[:, 33:48] = torch.randn(num_nodes, 15) * 0.5  # Other network features
        
        # Feature 48-63: behavioral features
        node_features[:, 48:] = torch.randn(num_nodes, 16) * 0.3
        
        # Generate realistic fraud labels with patterns
        fraud_probability = torch.sigmoid(
            node_features[:, 0] * 0.2 +  # High amounts more likely fraud
            node_features[:, 32] * 0.1 +  # High degree nodes more suspicious
            torch.randn(num_nodes) * 0.5   # Random component
        )
        
        fraud_mask = torch.rand(num_nodes) < fraud_probability * 0.15  # ~10-15% fraud rate
        labels = fraud_mask.long()
        
        hypergraph_data = HypergraphData(
            incidence_matrix=incidence_matrix,
            node_features=node_features,
            node_labels=labels
        )
        
        logger.info(f"Dataset created: {labels.sum().item()}/{num_nodes} fraud nodes ({labels.float().mean()*100:.1f}%)")
        
        return temporal_graph, hypergraph_data, node_features, labels
    
    def create_baseline_models(self, feature_dim: int, hidden_dim: int = 128) -> Dict[str, nn.Module]:
        """Create baseline models for comparison per Â§PHASE_D.1"""
        baseline_models = {}
        
        # Traditional GNN baselines
        baseline_models['GCN'] = SimpleGCN(
            in_dim=feature_dim, 
            hidden_dim=hidden_dim, 
            out_dim=2
        )
        
        baseline_models['GraphSAGE'] = SimpleGraphSAGE(
            in_dim=feature_dim,
            hidden_dim=hidden_dim, 
            out_dim=2
        )
        
        baseline_models['HAN'] = SimpleHAN(
            metadata=(['node'], [('node', 'edge', 'node')]),
            hidden_dim=hidden_dim,
            out_dim=2
        )
        
        # Hypergraph baseline (Stage 5)
        baseline_models['Hypergraph'] = create_hypergraph_model(
            input_dim=feature_dim,
            hidden_dim=hidden_dim,
            output_dim=2,
            model_config={'layer_type': 'full', 'num_layers': 3}
        )
        
        # Simplified HAN (feature-only for comparison)
        class SimplifiedHAN(nn.Module):
            def __init__(self, in_dim, hidden_dim, out_dim):
                super().__init__()
                self.linear1 = nn.Linear(in_dim, hidden_dim)
                self.linear2 = nn.Linear(hidden_dim, out_dim)
                self.dropout = nn.Dropout(0.3)
            
            def forward(self, x):
                x = F.relu(self.linear1(x))
                x = self.dropout(x)
                return self.linear2(x)
        
        baseline_models['HAN'] = SimplifiedHAN(feature_dim, hidden_dim, 2)
        
        logger.info(f"Created {len(baseline_models)} baseline models")
        return baseline_models
    
    def create_tdgnn_variants(self, temporal_graph: TemporalGraph, 
                            feature_dim: int, hidden_dim: int = 128) -> Dict[str, TDGNNHypergraphModel]:
        """Create TDGNN variants for ablation studies per Â§PHASE_D.2"""
        
        # Base hypergraph model
        base_model = create_hypergraph_model(
            input_dim=feature_dim,
            hidden_dim=hidden_dim,
            output_dim=2,
            model_config={'layer_type': 'full', 'num_layers': 3}
        )
        
        tdgnn_variants = {}
        
        # Main TDGNN + G-SAMPLER configuration
        gsampler_main = GSampler(
            csr_indptr=temporal_graph.indptr,
            csr_indices=temporal_graph.indices,
            csr_timestamps=temporal_graph.timestamps,
            device='cpu'
        )
        
        tdgnn_variants['TDGNN_Main'] = TDGNNHypergraphModel(
            base_model=base_model,
            gsampler=gsampler_main,
            temporal_graph=temporal_graph
        )
        
        # Create additional variants for ablation
        for variant_name, config in [
            ('TDGNN_Conservative', {'fanouts': [5, 3], 'delta_t': 50.0}),
            ('TDGNN_Aggressive', {'fanouts': [25, 15], 'delta_t': 500.0}),
            ('TDGNN_Balanced', {'fanouts': [15, 10], 'delta_t': 200.0}),
        ]:
            gsampler = GSampler(
                csr_indptr=temporal_graph.indptr,
                csr_indices=temporal_graph.indices,
                csr_timestamps=temporal_graph.timestamps,
                device='cpu'
            )
            
            variant_model = TDGNNHypergraphModel(
                base_model=create_hypergraph_model(
                    input_dim=feature_dim,
                    hidden_dim=hidden_dim,
                    output_dim=2,
                    model_config={'layer_type': 'full', 'num_layers': 3}
                ),
                gsampler=gsampler,
                temporal_graph=temporal_graph
            )
            
            tdgnn_variants[variant_name] = variant_model
        
        logger.info(f"Created {len(tdgnn_variants)} TDGNN variants")
        return tdgnn_variants
    
    def run_baseline_experiments(self, baseline_models: Dict[str, nn.Module], 
                                temporal_graph: TemporalGraph, 
                                node_features: torch.Tensor, 
                                labels: torch.Tensor) -> Dict[str, Dict[str, float]]:
        """Run baseline model experiments per Â§PHASE_D.1"""
        logger.info("Running baseline experiments...")
        
        results = {}
        
        # Create train/val/test split and edge_index for graph models
        num_nodes = len(labels)
        perm = torch.randperm(num_nodes)
        
        train_size = int(0.6 * num_nodes)
        val_size = int(0.2 * num_nodes)
        
        train_mask = torch.zeros(num_nodes, dtype=torch.bool)
        val_mask = torch.zeros(num_nodes, dtype=torch.bool)
        test_mask = torch.zeros(num_nodes, dtype=torch.bool)
        
        train_mask[perm[:train_size]] = True
        val_mask[perm[train_size:train_size + val_size]] = True
        test_mask[perm[train_size + val_size:]] = True
        
        # Create simple edge_index from temporal graph for traditional GNNs
        edges = []
        for src in range(temporal_graph.num_nodes):
            start_idx = temporal_graph.indptr[src].item()
            end_idx = temporal_graph.indptr[src + 1].item()
            for i in range(start_idx, end_idx):
                dst = temporal_graph.indices[i].item()
                edges.append([src, dst])
        
        if edges:
            edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()
        else:
            # Fallback: create self-loops if no edges
            edge_index = torch.stack([torch.arange(num_nodes), torch.arange(num_nodes)], dim=0)
        
        for model_name, model in baseline_models.items():
            logger.info(f"Training {model_name}...")
            
            start_time = time.time()
            
            # Setup training
            optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)
            criterion = torch.nn.CrossEntropyLoss()
            
            # Simple training loop for baselines
            best_val_acc = 0.0
            
            for epoch in range(20):  # Quick training for comparison
                model.train()
                
                if model_name == 'Hypergraph':
                    # Create minimal hypergraph data for hypergraph baseline
                    hypergraph_data = HypergraphData(
                        incidence_matrix=torch.eye(num_nodes),  # Simplified: each node is its own hyperedge
                        node_features=node_features,
                        node_labels=labels
                    )
                    
                    logits = model(hypergraph_data, node_features)
                elif model_name == 'HAN':
                    # HAN expects heterogeneous data - create simple homogeneous version
                    # For simplicity, treat as node feature-only model
                    logits = model(node_features)  # Will implement simplified forward
                else:
                    # For other baselines, use graph structure
                    logits = model(node_features, edge_index)
                
                loss = criterion(logits[train_mask], labels[train_mask])
                
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()
                
                # Validation
                if epoch % 5 == 0:
                    model.eval()
                    with torch.no_grad():
                        if model_name == 'Hypergraph':
                            val_logits = model(hypergraph_data, node_features)
                        elif model_name == 'HAN':
                            val_logits = model(node_features)
                        else:
                            val_logits = model(node_features, edge_index)
                        
                        val_preds = torch.softmax(val_logits[val_mask], dim=1)[:, 1]
                        val_metrics = compute_metrics(labels[val_mask].numpy(), val_preds.numpy())
                        
                        if val_metrics['accuracy'] > best_val_acc:
                            best_val_acc = val_metrics['accuracy']
            
            training_time = time.time() - start_time
            
            # Final evaluation
            model.eval()
            with torch.no_grad():
                if model_name == 'Hypergraph':
                    test_logits = model(hypergraph_data, node_features)
                elif model_name == 'HAN':
                    test_logits = model(node_features)
                else:
                    test_logits = model(node_features, edge_index)
                
                test_preds = torch.softmax(test_logits[test_mask], dim=1)[:, 1]
                test_metrics = compute_metrics(labels[test_mask].numpy(), test_preds.numpy())
            
            results[model_name] = {
                'test_auc': test_metrics['auc'],
                'test_accuracy': test_metrics['accuracy'],
                'test_f1': test_metrics['f1'],
                'test_precision': test_metrics['precision'],
                'test_recall': test_metrics['recall'],
                'training_time': training_time,
                'num_parameters': sum(p.numel() for p in model.parameters())
            }
            
            logger.info(f"{model_name} - AUC: {test_metrics['auc']:.4f}, Time: {training_time:.2f}s")
        
        return results
    
    def run_tdgnn_experiments(self, tdgnn_variants: Dict[str, TDGNNHypergraphModel],
                            labels: torch.Tensor) -> Dict[str, Dict[str, float]]:
        """Run TDGNN experiments with different configurations per Â§PHASE_D.2"""
        logger.info("Running TDGNN experiments...")
        
        results = {}
        
        # Create train/val/test split
        num_nodes = len(labels)
        perm = torch.randperm(num_nodes)
        
        train_size = int(0.6 * num_nodes)
        val_size = int(0.2 * num_nodes)
        
        train_mask = torch.zeros(num_nodes, dtype=torch.bool)
        val_mask = torch.zeros(num_nodes, dtype=torch.bool)
        test_mask = torch.zeros(num_nodes, dtype=torch.bool)
        
        train_mask[perm[:train_size]] = True
        val_mask[perm[train_size:train_size + val_size]] = True
        test_mask[perm[train_size + val_size:]] = True
        
        # Create data loaders
        train_seeds = torch.where(train_mask)[0]
        val_seeds = torch.where(val_mask)[0]
        test_seeds = torch.where(test_mask)[0]
        
        current_time = 1500.0  # Evaluation timestamp
        
        for variant_name, model in tdgnn_variants.items():
            logger.info(f"Training {variant_name}...")
            
            start_time = time.time()
            
            # Get configuration for this variant
            if 'Conservative' in variant_name:
                config = {'fanouts': [5, 3], 'delta_t': 50.0}
            elif 'Aggressive' in variant_name:
                config = {'fanouts': [25, 15], 'delta_t': 500.0}
            elif 'Balanced' in variant_name:
                config = {'fanouts': [15, 10], 'delta_t': 200.0}
            else:  # Main
                config = {'fanouts': [15, 10], 'delta_t': 200.0}
            
            # Create data loaders
            train_t_evals = torch.ones(len(train_seeds)) * current_time
            val_t_evals = torch.ones(len(val_seeds)) * current_time
            test_t_evals = torch.ones(len(test_seeds)) * current_time
            
            train_dataset = TensorDataset(train_seeds, train_t_evals, labels[train_seeds])
            val_dataset = TensorDataset(val_seeds, val_t_evals, labels[val_seeds])
            test_dataset = TensorDataset(test_seeds, test_t_evals, labels[test_seeds])
            
            train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
            val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)
            test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)
            
            # Setup training
            optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)
            criterion = torch.nn.CrossEntropyLoss()
            
            best_val_auc = 0.0
            
            # Training loop
            for epoch in range(15):  # Moderate training for comparison
                train_metrics = train_epoch(
                    model=model,
                    gsampler=model.gsampler,
                    train_seed_loader=train_loader,
                    optimizer=optimizer,
                    criterion=criterion,
                    cfg=config
                )
                
                # Validation every few epochs
                if epoch % 3 == 0:
                    val_metrics = evaluate_model(
                        model=model,
                        eval_loader=val_loader,
                        criterion=criterion,
                        cfg=config,
                        split_name='val'
                    )
                    
                    if val_metrics['val_accuracy'] > best_val_auc:
                        best_val_auc = val_metrics['val_accuracy']
            
            training_time = time.time() - start_time
            
            # Final test evaluation
            test_metrics = evaluate_model(
                model=model,
                eval_loader=test_loader,
                criterion=criterion,
                cfg=config,
                split_name='test'
            )
            
            # Collect detailed test predictions for metrics
            model.eval()
            all_test_probs = []
            all_test_labels = []
            
            with torch.no_grad():
                for seed_nodes, t_evals, batch_labels in test_loader:
                    logits = model(
                        seed_nodes=seed_nodes,
                        t_eval_array=t_evals,
                        fanouts=config['fanouts'],
                        delta_t=config['delta_t']
                    )
                    
                    probs = torch.softmax(logits, dim=1)[:, 1]
                    all_test_probs.append(probs.cpu())
                    all_test_labels.append(batch_labels.cpu())
            
            all_test_probs = torch.cat(all_test_probs, dim=0).numpy()
            all_test_labels = torch.cat(all_test_labels, dim=0).numpy()
            
            detailed_metrics = compute_metrics(all_test_labels, all_test_probs)
            
            results[variant_name] = {
                'test_auc': detailed_metrics['auc'],
                'test_accuracy': detailed_metrics['accuracy'],
                'test_f1': detailed_metrics['f1'],
                'test_precision': detailed_metrics['precision'],
                'test_recall': detailed_metrics['recall'],
                'training_time': training_time,
                'num_parameters': sum(p.numel() for p in model.parameters()),
                'config': config
            }
            
            logger.info(f"{variant_name} - AUC: {detailed_metrics['auc']:.4f}, Time: {training_time:.2f}s")
        
        return results
    
    def run_ablation_studies(self) -> Dict[str, Any]:
        """Run comprehensive ablation studies per Â§PHASE_D.2-D.3"""
        logger.info("Running ablation studies...")
        
        # Create smaller dataset for ablation studies
        temporal_graph, hypergraph_data, node_features, labels = self.create_synthetic_temporal_data(
            num_nodes=500, num_edges=1500, feature_dim=32
        )
        
        ablation_results = {}
        
        # 1. Sampling Strategy Ablation (recency vs uniform)
        ablation_results['sampling_strategy'] = self._ablation_sampling_strategy(
            temporal_graph, node_features, labels
        )
        
        # 2. Time Window (delta_t) Ablation
        ablation_results['delta_t_sensitivity'] = self._ablation_delta_t(
            temporal_graph, node_features, labels
        )
        
        # 3. Fanout Configuration Ablation
        ablation_results['fanout_analysis'] = self._ablation_fanouts(
            temporal_graph, node_features, labels
        )
        
        # 4. GPU vs CPU Performance Comparison
        ablation_results['gpu_cpu_comparison'] = self._ablation_gpu_cpu(
            temporal_graph, node_features, labels
        )
        
        return ablation_results
    
    def _ablation_sampling_strategy(self, temporal_graph: TemporalGraph, 
                                  node_features: torch.Tensor, labels: torch.Tensor) -> Dict[str, float]:
        """Ablation study on sampling strategies"""
        logger.info("Ablation: Sampling strategy (recency vs uniform)")
        
        # Note: In a full implementation, we would modify G-SAMPLER to support uniform sampling
        # For now, we'll simulate the comparison
        
        strategies = ['recency', 'uniform']
        results = {}
        
        for strategy in strategies:
            # Create TDGNN model
            base_model = create_hypergraph_model(
                input_dim=node_features.size(1),
                hidden_dim=64,
                output_dim=2,
                model_config={'layer_type': 'full', 'num_layers': 2}
            )
            
            gsampler = GSampler(
                csr_indptr=temporal_graph.indptr,
                csr_indices=temporal_graph.indices,
                csr_timestamps=temporal_graph.timestamps,
                device='cpu'
            )
            
            model = TDGNNHypergraphModel(
                base_model=base_model,
                gsampler=gsampler,
                temporal_graph=temporal_graph
            )
            
            # Quick evaluation (simplified)
            with torch.no_grad():
                test_seeds = torch.randint(0, len(labels), (50,))
                t_evals = torch.ones(50) * 1400.0
                
                # Simulate different sampling strategies by varying delta_t
                if strategy == 'recency':
                    delta_t = 100.0  # Restrictive - favors recent edges
                else:  # uniform
                    delta_t = 1000.0  # Permissive - more uniform sampling
                
                logits = model(
                    seed_nodes=test_seeds,
                    t_eval_array=t_evals,
                    fanouts=[10, 5],
                    delta_t=delta_t
                )
                
                probs = torch.softmax(logits, dim=1)[:, 1].numpy()
                test_labels = labels[test_seeds].numpy()
                
                metrics = compute_metrics(test_labels, probs)
                results[strategy] = metrics['auc']
        
        return results
    
    def _ablation_delta_t(self, temporal_graph: TemporalGraph, 
                         node_features: torch.Tensor, labels: torch.Tensor) -> Dict[str, float]:
        """Ablation study on delta_t parameter sensitivity"""
        logger.info("Ablation: Delta_t sensitivity analysis")
        
        delta_t_values = [10.0, 50.0, 100.0, 200.0, 500.0, 1000.0]
        results = {}
        
        # Create base model
        base_model = create_hypergraph_model(
            input_dim=node_features.size(1),
            hidden_dim=64,
            output_dim=2,
            model_config={'layer_type': 'full', 'num_layers': 2}
        )
        
        gsampler = GSampler(
            csr_indptr=temporal_graph.indptr,
            csr_indices=temporal_graph.indices,
            csr_timestamps=temporal_graph.timestamps,
            device='cpu'
        )
        
        model = TDGNNHypergraphModel(
            base_model=base_model,
            gsampler=gsampler,
            temporal_graph=temporal_graph
        )
        
        test_seeds = torch.randint(0, len(labels), (100,))
        t_evals = torch.ones(100) * 1400.0
        
        for delta_t in delta_t_values:
            with torch.no_grad():
                logits = model(
                    seed_nodes=test_seeds,
                    t_eval_array=t_evals,
                    fanouts=[15, 10],
                    delta_t=delta_t
                )
                
                probs = torch.softmax(logits, dim=1)[:, 1].numpy()
                test_labels = labels[test_seeds].numpy()
                
                metrics = compute_metrics(test_labels, probs)
                results[f'delta_t_{delta_t}'] = metrics['auc']
        
        return results
    
    def _ablation_fanouts(self, temporal_graph: TemporalGraph, 
                         node_features: torch.Tensor, labels: torch.Tensor) -> Dict[str, float]:
        """Ablation study on fanout configurations"""
        logger.info("Ablation: Fanout configuration analysis")
        
        fanout_configs = [
            [5, 3],     # Conservative
            [10, 5],    # Moderate
            [15, 10],   # Balanced
            [25, 15],   # Aggressive
            [50, 25]    # Very aggressive
        ]
        
        results = {}
        
        # Create base model
        base_model = create_hypergraph_model(
            input_dim=node_features.size(1),
            hidden_dim=64,
            output_dim=2,
            model_config={'layer_type': 'full', 'num_layers': 2}
        )
        
        gsampler = GSampler(
            csr_indptr=temporal_graph.indptr,
            csr_indices=temporal_graph.indices,
            csr_timestamps=temporal_graph.timestamps,
            device='cpu'
        )
        
        model = TDGNNHypergraphModel(
            base_model=base_model,
            gsampler=gsampler,
            temporal_graph=temporal_graph
        )
        
        test_seeds = torch.randint(0, len(labels), (100,))
        t_evals = torch.ones(100) * 1400.0
        
        for fanouts in fanout_configs:
            start_time = time.time()
            
            with torch.no_grad():
                logits = model(
                    seed_nodes=test_seeds,
                    t_eval_array=t_evals,
                    fanouts=fanouts,
                    delta_t=200.0
                )
                
                probs = torch.softmax(logits, dim=1)[:, 1].numpy()
                test_labels = labels[test_seeds].numpy()
                
                metrics = compute_metrics(test_labels, probs)
            
            sampling_time = time.time() - start_time
            
            config_name = f'fanouts_{fanouts[0]}_{fanouts[1]}'
            results[config_name] = {
                'auc': metrics['auc'],
                'sampling_time': sampling_time
            }
        
        return results
    
    def _ablation_gpu_cpu(self, temporal_graph: TemporalGraph, 
                         node_features: torch.Tensor, labels: torch.Tensor) -> Dict[str, float]:
        """GPU vs CPU performance comparison"""
        logger.info("Ablation: GPU vs CPU performance comparison")
        
        results = {}
        
        # Test on CPU (always available)
        cpu_gsampler = GSampler(
            csr_indptr=temporal_graph.indptr,
            csr_indices=temporal_graph.indices,
            csr_timestamps=temporal_graph.timestamps,
            device='cpu'
        )
        
        base_model = create_hypergraph_model(
            input_dim=node_features.size(1),
            hidden_dim=64,
            output_dim=2,
            model_config={'layer_type': 'full', 'num_layers': 2}
        )
        
        cpu_model = TDGNNHypergraphModel(
            base_model=base_model,
            gsampler=cpu_gsampler,
            temporal_graph=temporal_graph
        )
        
        test_seeds = torch.randint(0, len(labels), (200,))
        t_evals = torch.ones(200) * 1400.0
        
        # CPU timing
        start_time = time.time()
        with torch.no_grad():
            cpu_logits = cpu_model(
                seed_nodes=test_seeds,
                t_eval_array=t_evals,
                fanouts=[15, 10],
                delta_t=200.0
            )
        cpu_time = time.time() - start_time
        
        cpu_probs = torch.softmax(cpu_logits, dim=1)[:, 1].numpy()
        test_labels = labels[test_seeds].numpy()
        cpu_metrics = compute_metrics(test_labels, cpu_probs)
        
        results['cpu'] = {
            'auc': cpu_metrics['auc'],
            'inference_time': cpu_time,
            'device': 'cpu'
        }
        
        # GPU timing (if available)
        if torch.cuda.is_available():
            try:
                gpu_gsampler = GSampler(
                    csr_indptr=temporal_graph.indptr,
                    csr_indices=temporal_graph.indices,
                    csr_timestamps=temporal_graph.timestamps,
                    device='cuda'
                )
                
                gpu_model = TDGNNHypergraphModel(
                    base_model=base_model.cuda(),
                    gsampler=gpu_gsampler,
                    temporal_graph=temporal_graph
                ).cuda()
                
                # GPU timing
                torch.cuda.synchronize()
                start_time = time.time()
                
                with torch.no_grad():
                    gpu_logits = gpu_model(
                        seed_nodes=test_seeds.cuda(),
                        t_eval_array=t_evals.cuda(),
                        fanouts=[15, 10],
                        delta_t=200.0
                    )
                
                torch.cuda.synchronize()
                gpu_time = time.time() - start_time
                
                gpu_probs = torch.softmax(gpu_logits, dim=1)[:, 1].cpu().numpy()
                gpu_metrics = compute_metrics(test_labels, gpu_probs)
                
                results['gpu'] = {
                    'auc': gpu_metrics['auc'],
                    'inference_time': gpu_time,
                    'device': 'cuda',
                    'speedup': cpu_time / gpu_time if gpu_time > 0 else float('inf')
                }
                
            except Exception as e:
                logger.warning(f"GPU testing failed: {e}")
                results['gpu'] = {'error': str(e)}
        else:
            results['gpu'] = {'error': 'CUDA not available'}
        
        return results
    
    def save_results(self, all_results: Dict[str, Any]):
        """Save all experimental results"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # Save detailed results
        results_file = self.results_dir / f"stage6_experiments_{timestamp}.json"
        with open(results_file, 'w') as f:
            json.dump(all_results, f, indent=2, default=str)
        
        logger.info(f"Results saved to {results_file}")
        
        # Create summary report
        self.create_summary_report(all_results, timestamp)
    
    def create_summary_report(self, results: Dict[str, Any], timestamp: str):
        """Create human-readable summary report"""
        report_file = self.results_dir / f"stage6_summary_{timestamp}.txt"
        
        with open(report_file, 'w') as f:
            f.write("=" * 60 + "\n")
            f.write("STAGE 6 TDGNN + G-SAMPLER EXPERIMENTAL RESULTS\n")
            f.write("=" * 60 + "\n\n")
            
            f.write(f"Experiment Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            # Baseline Results
            if 'baseline_results' in results:
                f.write("BASELINE MODEL COMPARISON:\n")
                f.write("-" * 30 + "\n")
                for model, metrics in results['baseline_results'].items():
                    f.write(f"{model:15} | AUC: {metrics['test_auc']:.4f} | "
                           f"F1: {metrics['test_f1']:.4f} | Time: {metrics['training_time']:.2f}s\n")
                f.write("\n")
            
            # TDGNN Results
            if 'tdgnn_results' in results:
                f.write("TDGNN VARIANT COMPARISON:\n")
                f.write("-" * 30 + "\n")
                for model, metrics in results['tdgnn_results'].items():
                    f.write(f"{model:18} | AUC: {metrics['test_auc']:.4f} | "
                           f"F1: {metrics['test_f1']:.4f} | Time: {metrics['training_time']:.2f}s\n")
                f.write("\n")
            
            # Ablation Studies
            if 'ablation_results' in results:
                f.write("ABLATION STUDY RESULTS:\n")
                f.write("-" * 30 + "\n")
                
                for study_name, study_results in results['ablation_results'].items():
                    f.write(f"\n{study_name.upper()}:\n")
                    if isinstance(study_results, dict):
                        for config, value in study_results.items():
                            if isinstance(value, dict):
                                f.write(f"  {config}: AUC={value.get('auc', 'N/A'):.4f}\n")
                            else:
                                f.write(f"  {config}: {value:.4f}\n")
                    f.write("\n")
        
        logger.info(f"Summary report saved to {report_file}")

def run_phase_d_experiments():
    """Main function to run all Phase D experiments"""
    print("ğŸš€ Starting Stage 6 Phase D Experiments")
    print("=" * 50)
    
    # Initialize experiment framework
    framework = Stage6ExperimentFramework()
    
    # Create experimental dataset
    print("ğŸ“Š Creating experimental dataset...")
    temporal_graph, hypergraph_data, node_features, labels = framework.create_synthetic_temporal_data(
        num_nodes=800, num_edges=2000, feature_dim=64
    )
    
    # Run experiments
    all_results = {}
    
    # 1. Baseline experiments per Â§PHASE_D.1
    print("\nğŸ“ˆ Running baseline model comparison...")
    baseline_models = framework.create_baseline_models(feature_dim=64)
    all_results['baseline_results'] = framework.run_baseline_experiments(
        baseline_models, temporal_graph, node_features, labels
    )
    
    # 2. TDGNN experiments per Â§PHASE_D.2
    print("\nğŸ¯ Running TDGNN variant comparison...")
    tdgnn_variants = framework.create_tdgnn_variants(temporal_graph, feature_dim=64)
    all_results['tdgnn_results'] = framework.run_tdgnn_experiments(
        tdgnn_variants, labels
    )
    
    # 3. Ablation studies per Â§PHASE_D.3
    print("\nğŸ”¬ Running ablation studies...")
    all_results['ablation_results'] = framework.run_ablation_studies()
    
    # Save results
    print("\nğŸ’¾ Saving results...")
    framework.save_results(all_results)
    
    print("\nğŸ‰ Phase D experiments completed successfully!")
    print(f"ğŸ“ Results saved to: {framework.results_dir}")
    
    return all_results

if __name__ == "__main__":
    results = run_phase_d_experiments()
