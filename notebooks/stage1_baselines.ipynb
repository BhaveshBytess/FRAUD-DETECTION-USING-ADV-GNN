{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c603d34b",
   "metadata": {},
   "source": [
    "# Stage 1: Baseline Models\n",
    "\n",
    "This notebook is for training and evaluating baseline models on the Elliptic++ dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bb44bc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://data.pyg.org/whl/torch-2.8.0+cpu.html\n",
      "Requirement already satisfied: torch-scatter in c:\\users\\oumme\\onedrive\\desktop\\fraud detection\\.venv\\lib\\site-packages (2.1.2+pt28cpu)\n",
      "Requirement already satisfied: torch-sparse in c:\\users\\oumme\\onedrive\\desktop\\fraud detection\\.venv\\lib\\site-packages (0.6.18+pt28cpu)\n",
      "Requirement already satisfied: torch-cluster in c:\\users\\oumme\\onedrive\\desktop\\fraud detection\\.venv\\lib\\site-packages (1.6.3+pt28cpu)\n",
      "Requirement already satisfied: torch-spline-conv in c:\\users\\oumme\\onedrive\\desktop\\fraud detection\\.venv\\lib\\site-packages (1.2.2+pt28cpu)\n",
      "Requirement already satisfied: torch-geometric in c:\\users\\oumme\\onedrive\\desktop\\fraud detection\\.venv\\lib\\site-packages (2.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\oumme\\onedrive\\desktop\\fraud detection\\.venv\\lib\\site-packages (from torch-sparse) (1.16.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\oumme\\onedrive\\desktop\\fraud detection\\.venv\\lib\\site-packages (from torch-geometric) (3.12.15)\n",
      "Requirement already satisfied: fsspec in c:\\users\\oumme\\onedrive\\desktop\\fraud detection\\.venv\\lib\\site-packages (from torch-geometric) (2025.9.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\oumme\\onedrive\\desktop\\fraud detection\\.venv\\lib\\site-packages (from torch-geometric) (3.1.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\oumme\\onedrive\\desktop\\fraud detection\\.venv\\lib\\site-packages (from torch-geometric) (2.3.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\oumme\\onedrive\\desktop\\fraud detection\\.venv\\lib\\site-packages (from torch-geometric) (7.0.0)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\oumme\\onedrive\\desktop\\fraud detection\\.venv\\lib\\site-packages (from torch-geometric) (3.2.3)\n",
      "Requirement already satisfied: requests in c:\\users\\oumme\\onedrive\\desktop\\fraud detection\\.venv\\lib\\site-packages (from torch-geometric) (2.32.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\oumme\\onedrive\\desktop\\fraud detection\\.venv\\lib\\site-packages (from torch-geometric) (4.67.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\oumme\\onedrive\\desktop\\fraud detection\\.venv\\lib\\site-packages (from aiohttp->torch-geometric) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\oumme\\onedrive\\desktop\\fraud detection\\.venv\\lib\\site-packages (from aiohttp->torch-geometric) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\oumme\\onedrive\\desktop\\fraud detection\\.venv\\lib\\site-packages (from aiohttp->torch-geometric) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\oumme\\onedrive\\desktop\\fraud detection\\.venv\\lib\\site-packages (from aiohttp->torch-geometric) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\oumme\\onedrive\\desktop\\fraud detection\\.venv\\lib\\site-packages (from aiohttp->torch-geometric) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\oumme\\onedrive\\desktop\\fraud detection\\.venv\\lib\\site-packages (from aiohttp->torch-geometric) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\oumme\\onedrive\\desktop\\fraud detection\\.venv\\lib\\site-packages (from aiohttp->torch-geometric) (1.20.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\oumme\\onedrive\\desktop\\fraud detection\\.venv\\lib\\site-packages (from jinja2->torch-geometric) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\oumme\\onedrive\\desktop\\fraud detection\\.venv\\lib\\site-packages (from requests->torch-geometric) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\oumme\\onedrive\\desktop\\fraud detection\\.venv\\lib\\site-packages (from requests->torch-geometric) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\oumme\\onedrive\\desktop\\fraud detection\\.venv\\lib\\site-packages (from requests->torch-geometric) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\oumme\\onedrive\\desktop\\fraud detection\\.venv\\lib\\site-packages (from requests->torch-geometric) (2025.8.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\oumme\\onedrive\\desktop\\fraud detection\\.venv\\lib\\site-packages (from tqdm->torch-geometric) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "# Note: This assumes you are in a Colab/Kaggle environment.\n",
    "# For local execution, it's better to use the requirements.txt file.\n",
    "import sys\n",
    "!\"{sys.executable}\" -m pip install -q numpy pandas torch torchvision scikit-learn pyyaml\n",
    "!\"{sys.executable}\" -m pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-2.8.0+cpu.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e601f2b5",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "\n",
    "First, ensure your `ellipticpp.pt` file is accessible. If you are in Colab, you might need to upload it or mount your Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b3365b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We assume the data is in the parent `data` directory\n",
    "# If not, you may need to adjust the path.\n",
    "# For example, in Colab, you might have it at '/content/ellipticpp.pt'\n",
    "DATA_PATH = '../data/ellipticpp.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6bb7e8",
   "metadata": {},
   "source": [
    "## Run Baseline Training (Lite Mode)\n",
    "\n",
    "Here, we'll run the training script with a small sample of the data to quickly verify that everything works. We will test GCN, GraphSAGE, and a simplified RGCN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6982b531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training GCN ---\n",
      "Starting training for gcn...\n",
      "Epoch 0 loss 19.5084 val_auc 0.7498\n",
      "Epoch 1 loss 16.0915 val_auc 0.7750\n",
      "Epoch 2 loss 16.1378 val_auc 0.7710\n",
      "Epoch 3 loss 10.2079 val_auc 0.7356\n",
      "Epoch 4 loss 8.5931 val_auc 0.6339\n",
      "Final Test Metrics: {'auc': 0.5586854460093896, 'pr_auc': 0.9310536871586619, 'f1': 0.9594594594594594, 'precision': 0.922077922077922, 'recall': 1.0}\n",
      "\n",
      "--- Training GraphSAGE ---\n",
      "Starting training for gcn...\n",
      "Epoch 0 loss 19.5084 val_auc 0.7498\n",
      "Epoch 1 loss 16.0915 val_auc 0.7750\n",
      "Epoch 2 loss 16.1378 val_auc 0.7710\n",
      "Epoch 3 loss 10.2079 val_auc 0.7356\n",
      "Epoch 4 loss 8.5931 val_auc 0.6339\n",
      "Final Test Metrics: {'auc': 0.5586854460093896, 'pr_auc': 0.9310536871586619, 'f1': 0.9594594594594594, 'precision': 0.922077922077922, 'recall': 1.0}\n",
      "\n",
      "--- Training GraphSAGE ---\n",
      "Starting training for graphsage...\n",
      "Epoch 0 loss 3.1348 val_auc 0.8831\n",
      "Epoch 1 loss 2.8140 val_auc 0.8921\n",
      "Epoch 2 loss 1.3252 val_auc 0.8975\n",
      "Epoch 3 loss 1.4437 val_auc 0.8923\n",
      "Epoch 4 loss 1.2803 val_auc 0.8948\n",
      "Final Test Metrics: {'auc': 0.8251141552511414, 'pr_auc': 0.9698756500436133, 'f1': 0.9511400651465798, 'precision': 0.906832298136646, 'recall': 1.0}\n",
      "\n",
      "--- Training RGCN ---\n",
      "Starting training for graphsage...\n",
      "Epoch 0 loss 3.1348 val_auc 0.8831\n",
      "Epoch 1 loss 2.8140 val_auc 0.8921\n",
      "Epoch 2 loss 1.3252 val_auc 0.8975\n",
      "Epoch 3 loss 1.4437 val_auc 0.8923\n",
      "Epoch 4 loss 1.2803 val_auc 0.8948\n",
      "Final Test Metrics: {'auc': 0.8251141552511414, 'pr_auc': 0.9698756500436133, 'f1': 0.9511400651465798, 'precision': 0.906832298136646, 'recall': 1.0}\n",
      "\n",
      "--- Training RGCN ---\n",
      "Warning: RGCN baseline is simplified. It trains on all node types but only evaluates on transactions.\n",
      "Starting training for rgcn...\n",
      "Epoch 0 loss 0.6544 val_auc 0.8220\n",
      "Epoch 1 loss 0.4288 val_auc 0.6797\n",
      "Epoch 2 loss 0.7545 val_auc 0.8761\n",
      "Epoch 3 loss 0.3657 val_auc 0.8724\n",
      "Epoch 4 loss 0.4234 val_auc 0.8692\n",
      "Final Test Metrics: {'auc': 0.8777068415149686, 'pr_auc': 0.9856827209766473, 'f1': 0.958743842364532, 'precision': 0.9207569485511532, 'recall': 1.0}\n",
      "Warning: RGCN baseline is simplified. It trains on all node types but only evaluates on transactions.\n",
      "Starting training for rgcn...\n",
      "Epoch 0 loss 0.6544 val_auc 0.8220\n",
      "Epoch 1 loss 0.4288 val_auc 0.6797\n",
      "Epoch 2 loss 0.7545 val_auc 0.8761\n",
      "Epoch 3 loss 0.3657 val_auc 0.8724\n",
      "Epoch 4 loss 0.4234 val_auc 0.8692\n",
      "Final Test Metrics: {'auc': 0.8777068415149686, 'pr_auc': 0.9856827209766473, 'f1': 0.958743842364532, 'precision': 0.9207569485511532, 'recall': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Run the training script from the parent directory\n",
    "# We need to change the working directory to the project root\n",
    "import os\n",
    "import sys\n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    os.chdir('..')\n",
    "if os.getcwd() not in sys.path:\n",
    "    sys.path.append(os.getcwd())\n",
    "\n",
    "# Train GCN\n",
    "print(\"--- Training GCN ---\")\n",
    "!python src/train_baseline.py --model gcn --out_dir experiments/baseline/lite_gcn --epochs 5 --sample 1000\n",
    "\n",
    "# Train GraphSAGE\n",
    "print(\"\\n--- Training GraphSAGE ---\")\n",
    "!python src/train_baseline.py --model graphsage --out_dir experiments/baseline/lite_graphsage --epochs 5 --sample 1000\n",
    "\n",
    "# Train RGCN\n",
    "# Note: The RGCN baseline is simplified and may not perform well without proper heterogeneous handling.\n",
    "print(\"\\n--- Training RGCN ---\")\n",
    "!python src/train_baseline.py --model rgcn --out_dir experiments/baseline/lite_rgcn --epochs 5 --sample 50000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1771bc6e",
   "metadata": {},
   "source": [
    "## Evaluate the Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6559848e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- GCN Evaluation ---\n",
      "Evaluation Metrics:\n",
      "{\n",
      "    \"auc\": 0.5661764705882353,\n",
      "    \"pr_auc\": 0.8922645627227593,\n",
      "    \"f1\": 0.9347079037800687,\n",
      "    \"precision\": 0.8774193548387097,\n",
      "    \"recall\": 1.0\n",
      "}\n",
      "\n",
      "--- GraphSAGE Evaluation ---\n",
      "Evaluation Metrics:\n",
      "{\n",
      "    \"auc\": 0.5661764705882353,\n",
      "    \"pr_auc\": 0.8922645627227593,\n",
      "    \"f1\": 0.9347079037800687,\n",
      "    \"precision\": 0.8774193548387097,\n",
      "    \"recall\": 1.0\n",
      "}\n",
      "\n",
      "--- GraphSAGE Evaluation ---\n",
      "Evaluation Metrics:\n",
      "{\n",
      "    \"auc\": 0.9629090909090909,\n",
      "    \"pr_auc\": 0.9967456720839039,\n",
      "    \"f1\": 0.9578544061302682,\n",
      "    \"precision\": 0.9191176470588235,\n",
      "    \"recall\": 1.0\n",
      "}\n",
      "\n",
      "--- RGCN Evaluation ---\n",
      "Evaluation Metrics:\n",
      "{\n",
      "    \"auc\": 0.9629090909090909,\n",
      "    \"pr_auc\": 0.9967456720839039,\n",
      "    \"f1\": 0.9578544061302682,\n",
      "    \"precision\": 0.9191176470588235,\n",
      "    \"recall\": 1.0\n",
      "}\n",
      "\n",
      "--- RGCN Evaluation ---\n",
      "Evaluation Metrics:\n",
      "{\n",
      "    \"auc\": 0.8524355828220858,\n",
      "    \"pr_auc\": 0.9753117857999312,\n",
      "    \"f1\": 0.9484666455896301,\n",
      "    \"precision\": 0.9019843656043295,\n",
      "    \"recall\": 1.0\n",
      "}\n",
      "Evaluation Metrics:\n",
      "{\n",
      "    \"auc\": 0.8524355828220858,\n",
      "    \"pr_auc\": 0.9753117857999312,\n",
      "    \"f1\": 0.9484666455896301,\n",
      "    \"precision\": 0.9019843656043295,\n",
      "    \"recall\": 1.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"--- GCN Evaluation ---\")\n",
    "!python src/eval.py --model gcn --ckpt experiments/baseline/lite_gcn/ckpt.pth --sample 1000\n",
    "\n",
    "print(\"\\n--- GraphSAGE Evaluation ---\")\n",
    "!python src/eval.py --model graphsage --ckpt experiments/baseline/lite_graphsage/ckpt.pth --sample 1000\n",
    "\n",
    "print(\"\\n--- RGCN Evaluation ---\")\n",
    "!python src/eval.py --model rgcn --ckpt experiments/baseline/lite_rgcn/ckpt.pth --sample 50000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8432fa9f",
   "metadata": {},
   "source": [
    "## Check the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "05e3ee06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for GCN:\n",
      "{\n",
      "    \"auc\": 0.5586854460093896,\n",
      "    \"pr_auc\": 0.9310536871586619,\n",
      "    \"f1\": 0.9594594594594594,\n",
      "    \"precision\": 0.922077922077922,\n",
      "    \"recall\": 1.0\n",
      "}\n",
      "Metrics for GraphSAGE:\n",
      "{\n",
      "    \"auc\": 0.8251141552511414,\n",
      "    \"pr_auc\": 0.9698756500436133,\n",
      "    \"f1\": 0.9511400651465798,\n",
      "    \"precision\": 0.906832298136646,\n",
      "    \"recall\": 1.0\n",
      "}\n",
      "Metrics for RGCN:\n",
      "{\n",
      "    \"auc\": 0.8777068415149686,\n",
      "    \"pr_auc\": 0.9856827209766473,\n",
      "    \"f1\": 0.958743842364532,\n",
      "    \"precision\": 0.9207569485511532,\n",
      "    \"recall\": 1.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def print_metrics(model_name, path):\n",
    "    try:\n",
    "        with open(path, 'r') as f:\n",
    "            metrics = json.load(f)\n",
    "        print(f\"Metrics for {model_name}:\")\n",
    "        print(json.dumps(metrics, indent=4))\n",
    "    except FileNotFoundError:\n",
    "        print(f\"metrics.json not found for {model_name}. Did the training script run successfully?\")\n",
    "\n",
    "print_metrics(\"GCN\", \"experiments/baseline/lite_gcn/metrics.json\")\n",
    "print_metrics(\"GraphSAGE\", \"experiments/baseline/lite_graphsage/metrics.json\")\n",
    "print_metrics(\"RGCN\", \"experiments/baseline/lite_rgcn/metrics.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec411121",
   "metadata": {},
   "source": [
    "## Stage 1.2: Classical Baselines\n",
    "\n",
    "Now, let's train and evaluate classical machine learning models (Logistic Regression and Random Forest) on the node features to establish a non-GNN baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "343f8da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Logistic Regression ---\n",
      "--- Evaluating Logistic Regression ---\n",
      "Metrics for Logistic Regression:\n",
      "{\n",
      "    \"auc\": 0.9675189304784065,\n",
      "    \"pr_auc\": 0.9962562593245183,\n",
      "    \"f1\": 0.9774386197743862,\n",
      "    \"precision\": 0.970995385629532,\n",
      "    \"recall\": 0.9839679358717435\n",
      "}\n",
      "\n",
      "\n",
      "--- Training Random Forest ---\n",
      "--- Evaluating Random Forest ---\n",
      "Metrics for Random Forest:\n",
      "{\n",
      "    \"auc\": 0.9960144001649832,\n",
      "    \"pr_auc\": 0.9995579850479792,\n",
      "    \"f1\": 0.9904005296259517,\n",
      "    \"precision\": 0.9816272965879265,\n",
      "    \"recall\": 0.9993319973279893\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from src.metrics import compute_metrics\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- 1. Load and Prepare Data ---\n",
    "# We'll reuse the data loading logic concept from the GNN scripts\n",
    "# to get the same training, validation, and test splits.\n",
    "\n",
    "# Define the data path\n",
    "DATA_PATH = 'data/ellipticpp/ellipticpp.pt'\n",
    "\n",
    "# Load the full dataset\n",
    "full_data = torch.load(DATA_PATH, weights_only=False)\n",
    "tx_data = full_data['transaction']\n",
    "\n",
    "# Ensure masks exist\n",
    "if not hasattr(tx_data, 'train_mask') or tx_data.train_mask is None:\n",
    "    num_tx_nodes = tx_data.num_nodes\n",
    "    perm = torch.randperm(num_tx_nodes)\n",
    "    tx_data.train_mask = torch.zeros(num_tx_nodes, dtype=torch.bool); tx_data.train_mask[perm[:int(0.7*num_tx_nodes)]] = True\n",
    "    tx_data.val_mask = torch.zeros(num_tx_nodes, dtype=torch.bool); tx_data.val_mask[perm[int(0.7*num_tx_nodes):int(0.85*num_tx_nodes)]] = True\n",
    "    tx_data.test_mask = torch.zeros(num_tx_nodes, dtype=torch.bool); tx_data.test_mask[perm[int(0.85*num_tx_nodes):]] = True\n",
    "\n",
    "# Filter out unknown labels (y=3)\n",
    "known_mask = tx_data.y != 3\n",
    "\n",
    "# Get features and impute NaNs\n",
    "X = tx_data.x[known_mask].numpy()\n",
    "X[np.isnan(X)] = 0\n",
    "\n",
    "# Get labels and remap: licit (1) -> 0, illicit (2) -> 1\n",
    "y = tx_data.y[known_mask].numpy()\n",
    "y[y == 1] = 0\n",
    "y[y == 2] = 1\n",
    "\n",
    "# Get masks\n",
    "train_mask = tx_data.train_mask[known_mask].numpy()\n",
    "test_mask = tx_data.test_mask[known_mask].numpy()\n",
    "\n",
    "X_train, y_train = X[train_mask], y[train_mask]\n",
    "X_test, y_test = X[test_mask], y[test_mask]\n",
    "\n",
    "# --- 2. Train and Evaluate Models ---\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"--- Training {name} ---\")\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"--- Evaluating {name} ---\")\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    metrics = compute_metrics(y_test, y_pred_proba)\n",
    "    results[name] = metrics\n",
    "    \n",
    "    print(f\"Metrics for {name}:\")\n",
    "    print(json.dumps(metrics, indent=4))\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
