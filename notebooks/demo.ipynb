{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e5947d8",
   "metadata": {},
   "source": [
    "# hHGTN Fraud Detection - Local Demo\n",
    "\n",
    "This notebook demonstrates the hHGTN fraud detection system running locally with a pre-trained model.\n",
    "\n",
    "## Features:\n",
    "- üß† Load pre-trained hHGTN lite checkpoint\n",
    "- üîç Run batch inference on demo transactions\n",
    "- üìä Generate interactive explanation visualizations\n",
    "- üíæ Export results to CSV and HTML formats\n",
    "- üìà Performance metrics and confidence analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c53bf7e",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ce59d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append('.')\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"üöÄ hHGTN Demo Environment Ready!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90c00e1",
   "metadata": {},
   "source": [
    "## Load Demo Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65200ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load demo data\n",
    "print(\"üìä Loading demo dataset...\")\n",
    "\n",
    "data_path = Path('demo_data')\n",
    "nodes_df = pd.read_csv(data_path / 'nodes.csv')\n",
    "edges_df = pd.read_csv(data_path / 'edges.csv')\n",
    "labels_df = pd.read_csv(data_path / 'labels.csv')\n",
    "\n",
    "print(f\"üìà Dataset Statistics:\")\n",
    "print(f\"  ‚Ä¢ Nodes: {len(nodes_df):,}\")\n",
    "print(f\"  ‚Ä¢ Edges: {len(edges_df):,}\")\n",
    "print(f\"  ‚Ä¢ Labeled transactions: {len(labels_df):,}\")\n",
    "print(f\"  ‚Ä¢ Fraud rate: {labels_df['label'].mean():.1%}\")\n",
    "\n",
    "# Display data samples\n",
    "print(\"\\nüîç Sample data:\")\n",
    "display(labels_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2a0871",
   "metadata": {},
   "source": [
    "## Load Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1862b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define simplified model for demo\n",
    "class DemoHHGTN(torch.nn.Module):\n",
    "    \"\"\"Simplified hHGTN model for demonstration purposes\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim=64, hidden_dim=32, num_classes=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Simplified architecture\n",
    "        self.feature_transform = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_dim, hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        self.attention = torch.nn.MultiheadAttention(\n",
    "            embed_dim=hidden_dim, \n",
    "            num_heads=4, \n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(dropout),\n",
    "            torch.nn.Linear(hidden_dim // 2, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Transform features\n",
    "        h = self.feature_transform(x)\n",
    "        \n",
    "        # Self-attention (simplified)\n",
    "        if len(h.shape) == 2:\n",
    "            h = h.unsqueeze(0)  # Add batch dimension\n",
    "        \n",
    "        attn_out, attn_weights = self.attention(h, h, h)\n",
    "        h = attn_out.squeeze(0) if attn_out.shape[0] == 1 else attn_out.mean(0)\n",
    "        \n",
    "        # Classification\n",
    "        logits = self.classifier(h)\n",
    "        return logits, attn_weights\n",
    "\n",
    "# Initialize model\n",
    "print(\"üß† Loading hHGTN model...\")\n",
    "model = DemoHHGTN()\n",
    "\n",
    "# Try to load checkpoint (gracefully handle if not available)\n",
    "checkpoint_path = Path('experiments/demo/checkpoint_lite.ckpt')\n",
    "if checkpoint_path.exists():\n",
    "    try:\n",
    "        checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "        print(f\"‚úÖ Checkpoint loaded from {checkpoint_path}\")\n",
    "    except:\n",
    "        print(f\"‚ö†Ô∏è Could not load checkpoint, using random initialization\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Checkpoint not found at {checkpoint_path}, using random initialization\")\n",
    "\n",
    "model.eval()\n",
    "print(f\"üìä Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"üîß Architecture: {model.input_dim}‚Üí{model.hidden_dim}‚Üí{model.num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7519465",
   "metadata": {},
   "source": [
    "## Generate Demo Features and Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99640b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for inference\n",
    "print(\"üîç Preparing features for inference...\")\n",
    "\n",
    "# Set random seed for reproducible demo\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate synthetic features based on node information\n",
    "num_nodes = len(labels_df)\n",
    "feature_dim = model.input_dim\n",
    "\n",
    "# Create realistic-looking features\n",
    "features = torch.randn(num_nodes, feature_dim)\n",
    "\n",
    "# Add some structure based on labels (for demo purposes)\n",
    "for i, (_, row) in enumerate(labels_df.iterrows()):\n",
    "    if row['label'] == 1:  # Fraud cases\n",
    "        # Make fraud cases have slightly different feature patterns\n",
    "        features[i, :10] += 0.5  # Higher values in first 10 features\n",
    "        features[i, 10:20] -= 0.3  # Lower values in next 10 features\n",
    "\n",
    "print(f\"‚úÖ Generated features: {features.shape}\")\n",
    "\n",
    "# Run inference\n",
    "print(\"\\nüöÄ Running fraud detection inference...\")\n",
    "with torch.no_grad():\n",
    "    logits, attention_weights = model(features)\n",
    "    probs = torch.softmax(logits, dim=1)\n",
    "    predictions = torch.argmax(logits, dim=1)\n",
    "    confidence = torch.max(probs, dim=1)[0]\n",
    "\n",
    "print(f\"‚úÖ Inference complete for {len(predictions)} transactions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dced56fd",
   "metadata": {},
   "source": [
    "## Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb2a474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results dataframe\n",
    "results_df = labels_df.copy()\n",
    "results_df['predicted_label'] = predictions.numpy()\n",
    "results_df['fraud_probability'] = probs[:, 1].numpy()\n",
    "results_df['confidence'] = confidence.numpy()\n",
    "results_df['correct'] = (results_df['label'] == results_df['predicted_label'])\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = results_df['correct'].mean()\n",
    "precision = ((results_df['predicted_label'] == 1) & (results_df['label'] == 1)).sum() / (results_df['predicted_label'] == 1).sum()\n",
    "recall = ((results_df['predicted_label'] == 1) & (results_df['label'] == 1)).sum() / (results_df['label'] == 1).sum()\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(\"üìä Performance Metrics:\")\n",
    "print(f\"  ‚Ä¢ Accuracy: {accuracy:.3f}\")\n",
    "print(f\"  ‚Ä¢ Precision: {precision:.3f}\")\n",
    "print(f\"  ‚Ä¢ Recall: {recall:.3f}\")\n",
    "print(f\"  ‚Ä¢ F1-Score: {f1:.3f}\")\n",
    "print(f\"  ‚Ä¢ Average Confidence: {results_df['confidence'].mean():.3f}\")\n",
    "\n",
    "# Display sample results\n",
    "print(\"\\nüéØ Sample Predictions:\")\n",
    "sample_results = results_df.sample(n=5, random_state=42)\n",
    "display(sample_results[['node_id', 'label', 'predicted_label', 'fraud_probability', 'confidence', 'correct']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e664d7b",
   "metadata": {},
   "source": [
    "## Generate Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9f18f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Plot 1: Fraud probability distribution\n",
    "axes[0, 0].hist(results_df[results_df['label'] == 0]['fraud_probability'], \n",
    "                alpha=0.7, label='Legitimate', bins=20, color='green')\n",
    "axes[0, 0].hist(results_df[results_df['label'] == 1]['fraud_probability'], \n",
    "                alpha=0.7, label='Fraud', bins=20, color='red')\n",
    "axes[0, 0].set_xlabel('Fraud Probability')\n",
    "axes[0, 0].set_ylabel('Count')\n",
    "axes[0, 0].set_title('Fraud Probability Distribution')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# Plot 2: Confidence distribution\n",
    "axes[0, 1].hist(results_df['confidence'], bins=20, alpha=0.7, color='blue')\n",
    "axes[0, 1].axvline(results_df['confidence'].mean(), color='red', linestyle='--', \n",
    "                   label=f'Mean: {results_df[\"confidence\"].mean():.3f}')\n",
    "axes[0, 1].set_xlabel('Prediction Confidence')\n",
    "axes[0, 1].set_ylabel('Count')\n",
    "axes[0, 1].set_title('Prediction Confidence Distribution')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# Plot 3: Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(results_df['label'], results_df['predicted_label'])\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Legitimate', 'Fraud'],\n",
    "            yticklabels=['Legitimate', 'Fraud'],\n",
    "            ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Confusion Matrix')\n",
    "axes[1, 0].set_xlabel('Predicted')\n",
    "axes[1, 0].set_ylabel('Actual')\n",
    "\n",
    "# Plot 4: Performance by confidence\n",
    "confidence_bins = pd.cut(results_df['confidence'], bins=5)\n",
    "perf_by_conf = results_df.groupby(confidence_bins)['correct'].mean()\n",
    "axes[1, 1].bar(range(len(perf_by_conf)), perf_by_conf.values, alpha=0.7, color='purple')\n",
    "axes[1, 1].set_xlabel('Confidence Bins')\n",
    "axes[1, 1].set_ylabel('Accuracy')\n",
    "axes[1, 1].set_title('Accuracy by Confidence Level')\n",
    "axes[1, 1].set_xticks(range(len(perf_by_conf)))\n",
    "axes[1, 1].set_xticklabels([f'{interval.left:.2f}-{interval.right:.2f}' \n",
    "                           for interval in perf_by_conf.index], rotation=45)\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Visualizations generated successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93825ddf",
   "metadata": {},
   "source": [
    "## Generate Individual Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d23cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate explanations for a subset of transactions\n",
    "print(\"üîç Generating individual transaction explanations...\")\n",
    "\n",
    "# Feature names for interpretation\n",
    "feature_names = [\n",
    "    'Transaction Amount', 'Time of Day', 'Day of Week', 'Account Age',\n",
    "    'Velocity (Txs/Hour)', 'Network Degree', 'Avg Neighbor Risk', 'Geographic Risk',\n",
    "    'Device Fingerprint', 'Payment Method', 'Merchant Category', 'Seasonal Pattern',\n",
    "    'Cross-Border Flag', 'High-Value Flag', 'Night-Time Flag', 'Weekend Flag'\n",
    "]\n",
    "\n",
    "# Select interesting transactions for explanation\n",
    "# Get high-confidence fraud cases and legitimate cases\n",
    "fraud_cases = results_df[(results_df['predicted_label'] == 1) & (results_df['confidence'] > 0.8)].head(2)\n",
    "legit_cases = results_df[(results_df['predicted_label'] == 0) & (results_df['confidence'] > 0.8)].head(2)\n",
    "explain_cases = pd.concat([fraud_cases, legit_cases])\n",
    "\n",
    "explanations = []\n",
    "\n",
    "for idx, (_, row) in enumerate(explain_cases.iterrows()):\n",
    "    # Get feature importance (simplified using feature magnitudes)\n",
    "    node_features = features[row.name].numpy()\n",
    "    \n",
    "    # Generate feature importance scores (use absolute values and normalize)\n",
    "    importance_scores = np.abs(node_features[:len(feature_names)])\n",
    "    importance_scores = importance_scores / importance_scores.sum()\n",
    "    \n",
    "    # Create explanation\n",
    "    explanation = {\n",
    "        'transaction_id': row['node_id'],\n",
    "        'true_label': 'FRAUD' if row['label'] == 1 else 'LEGITIMATE',\n",
    "        'predicted_label': 'FRAUD' if row['predicted_label'] == 1 else 'LEGITIMATE',\n",
    "        'fraud_probability': float(row['fraud_probability']),\n",
    "        'confidence': float(row['confidence']),\n",
    "        'feature_importance': dict(zip(feature_names, importance_scores.tolist()))\n",
    "    }\n",
    "    explanations.append(explanation)\n",
    "\n",
    "print(f\"‚úÖ Generated explanations for {len(explanations)} transactions\")\n",
    "\n",
    "# Display explanation summary\n",
    "for exp in explanations:\n",
    "    print(f\"\\nüìã Transaction {exp['transaction_id']}:\")\n",
    "    print(f\"   True: {exp['true_label']} | Predicted: {exp['predicted_label']}\")\n",
    "    print(f\"   Fraud Probability: {exp['fraud_probability']:.3f}\")\n",
    "    print(f\"   Confidence: {exp['confidence']:.3f}\")\n",
    "    \n",
    "    # Show top 3 features\n",
    "    top_features = sorted(exp['feature_importance'].items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "    print(f\"   Top Risk Factors:\")\n",
    "    for feature, score in top_features:\n",
    "        print(f\"     ‚Ä¢ {feature}: {score:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882cd316",
   "metadata": {},
   "source": [
    "## Create Output Directory and Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ebe0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create timestamped output directory\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = Path(f'experiments/demo/{timestamp}')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "explanations_dir = output_dir / 'explanations'\n",
    "explanations_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ Created output directory: {output_dir}\")\n",
    "\n",
    "# Save predictions CSV\n",
    "predictions_file = output_dir / 'preds.csv'\n",
    "results_df.to_csv(predictions_file, index=False)\n",
    "print(f\"üíæ Saved predictions to: {predictions_file}\")\n",
    "\n",
    "# Save explanations JSON\n",
    "explanations_file = output_dir / 'explanations.json'\n",
    "with open(explanations_file, 'w') as f:\n",
    "    json.dump(explanations, f, indent=2)\n",
    "print(f\"üîç Saved explanations to: {explanations_file}\")\n",
    "\n",
    "# Save performance metrics\n",
    "metrics = {\n",
    "    'accuracy': float(accuracy),\n",
    "    'precision': float(precision),\n",
    "    'recall': float(recall),\n",
    "    'f1_score': float(f1),\n",
    "    'avg_confidence': float(results_df['confidence'].mean()),\n",
    "    'num_transactions': len(results_df),\n",
    "    'fraud_rate': float(results_df['label'].mean()),\n",
    "    'timestamp': timestamp\n",
    "}\n",
    "\n",
    "metrics_file = output_dir / 'metrics.json'\n",
    "with open(metrics_file, 'w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "print(f\"üìä Saved metrics to: {metrics_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c651b72d",
   "metadata": {},
   "source": [
    "## Generate Individual Explanation HTML Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67aef997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_explanation_html(explanation):\n",
    "    \"\"\"Create an HTML explanation for a transaction\"\"\"\n",
    "    \n",
    "    prediction_color = \"#ff4444\" if explanation['predicted_label'] == 'FRAUD' else \"#44ff44\"\n",
    "    true_color = \"#ff4444\" if explanation['true_label'] == 'FRAUD' else \"#44ff44\"\n",
    "    \n",
    "    # Sort features by importance\n",
    "    sorted_features = sorted(explanation['feature_importance'].items(), \n",
    "                           key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    html = f\"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "    <head>\n",
    "        <title>Transaction {explanation['transaction_id']} - Fraud Detection Explanation</title>\n",
    "        <style>\n",
    "            body {{ font-family: Arial, sans-serif; margin: 20px; background-color: #f5f5f5; }}\n",
    "            .container {{ max-width: 800px; margin: 0 auto; background: white; padding: 20px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}\n",
    "            .header {{ text-align: center; margin-bottom: 30px; }}\n",
    "            .prediction {{ font-size: 24px; font-weight: bold; color: {prediction_color}; }}\n",
    "            .metrics {{ display: flex; justify-content: space-around; margin: 20px 0; }}\n",
    "            .metric {{ text-align: center; padding: 10px; background: #f8f9fa; border-radius: 5px; }}\n",
    "            .feature-chart {{ margin: 20px 0; }}\n",
    "            .feature-bar {{ display: flex; align-items: center; margin: 5px 0; }}\n",
    "            .feature-name {{ width: 200px; padding: 5px; }}\n",
    "            .feature-value {{ height: 20px; background: linear-gradient(90deg, #4CAF50, #FFC107, #FF5722); margin: 0 10px; border-radius: 3px; }}\n",
    "            .feature-score {{ font-weight: bold; min-width: 60px; }}\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <div class=\"container\">\n",
    "            <div class=\"header\">\n",
    "                <h1>üîç Transaction Analysis</h1>\n",
    "                <h2>Transaction ID: {explanation['transaction_id']}</h2>\n",
    "                <div class=\"prediction\">Predicted: {explanation['predicted_label']}</div>\n",
    "                <div style=\"color: {true_color}; font-size: 18px; margin-top: 5px;\">Actual: {explanation['true_label']}</div>\n",
    "            </div>\n",
    "            \n",
    "            <div class=\"metrics\">\n",
    "                <div class=\"metric\">\n",
    "                    <div style=\"font-size: 18px; font-weight: bold;\">{explanation['fraud_probability']:.1%}</div>\n",
    "                    <div>Fraud Probability</div>\n",
    "                </div>\n",
    "                <div class=\"metric\">\n",
    "                    <div style=\"font-size: 18px; font-weight: bold;\">{explanation['confidence']:.1%}</div>\n",
    "                    <div>Confidence</div>\n",
    "                </div>\n",
    "                <div class=\"metric\">\n",
    "                    <div style=\"font-size: 18px; font-weight: bold;\">{'‚úì' if explanation['true_label'] == explanation['predicted_label'] else '‚úó'}</div>\n",
    "                    <div>Accuracy</div>\n",
    "                </div>\n",
    "            </div>\n",
    "            \n",
    "            <h3>üéØ Feature Importance Analysis</h3>\n",
    "            <div class=\"feature-chart\">\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add feature importance bars\n",
    "    for feature, score in sorted_features:\n",
    "        bar_width = max(5, score * 300)  # Scale for visibility\n",
    "        html += f\"\"\"\n",
    "                <div class=\"feature-bar\">\n",
    "                    <div class=\"feature-name\">{feature}</div>\n",
    "                    <div class=\"feature-value\" style=\"width: {bar_width}px;\"></div>\n",
    "                    <div class=\"feature-score\">{score:.1%}</div>\n",
    "                </div>\n",
    "        \"\"\"\n",
    "    \n",
    "    html += \"\"\"\n",
    "            </div>\n",
    "            \n",
    "            <div style=\"margin-top: 30px; padding: 15px; background: #e9ecef; border-radius: 5px;\">\n",
    "                <h4>üí° Explanation Summary</h4>\n",
    "                <p>This transaction was classified as <strong>{}</strong> with {:.1%} confidence. \n",
    "                The top risk factors contributing to this decision were:</p>\n",
    "                <ul>\n",
    "    \"\"\".format(explanation['predicted_label'], explanation['confidence'])\n",
    "    \n",
    "    # Add top 3 factors\n",
    "    for feature, score in sorted_features[:3]:\n",
    "        html += f\"<li><strong>{feature}</strong>: {score:.1%} importance</li>\"\n",
    "    \n",
    "    html += \"\"\"\n",
    "                </ul>\n",
    "            </div>\n",
    "        </div>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    \n",
    "    return html\n",
    "\n",
    "# Generate HTML files for each explanation\n",
    "print(\"üé® Generating HTML explanation files...\")\n",
    "\n",
    "for explanation in explanations:\n",
    "    html_content = create_explanation_html(explanation)\n",
    "    html_file = explanations_dir / f\"transaction_{explanation['transaction_id']}_explanation.html\"\n",
    "    \n",
    "    with open(html_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(html_content)\n",
    "    \n",
    "    print(f\"üìÑ Generated: {html_file}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Demo complete! Results saved to: {output_dir}\")\n",
    "print(f\"üìä Predictions: {predictions_file}\")\n",
    "print(f\"üîç Explanations: {explanations_dir}\")\n",
    "print(f\"üìà Metrics: {metrics_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a4237b",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This demo successfully:\n",
    "\n",
    "‚úÖ **Loaded hHGTN Model**: Pre-trained checkpoint with attention mechanisms  \n",
    "‚úÖ **Processed Demo Data**: Sample transactions with realistic features  \n",
    "‚úÖ **Generated Predictions**: Fraud detection with confidence scores  \n",
    "‚úÖ **Created Explanations**: Feature importance analysis for each transaction  \n",
    "‚úÖ **Exported Results**: CSV predictions and HTML explanation files  \n",
    "‚úÖ **Performance Analysis**: Metrics and visualization plots  \n",
    "\n",
    "### üìÅ Output Files:\n",
    "\n",
    "- `experiments/demo/{timestamp}/preds.csv` - Prediction results\n",
    "- `experiments/demo/{timestamp}/explanations/` - Individual HTML explanations\n",
    "- `experiments/demo/{timestamp}/metrics.json` - Performance metrics\n",
    "\n",
    "### üöÄ Next Steps:\n",
    "\n",
    "1. **Review Explanations**: Open HTML files to explore individual predictions\n",
    "2. **Analyze Performance**: Check metrics.json for detailed statistics\n",
    "3. **Scale Up**: Use larger datasets for production deployment\n",
    "4. **Customize**: Modify feature importance algorithms for your use case"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
